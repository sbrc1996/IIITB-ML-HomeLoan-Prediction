{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING ESSENTIAL LIBARARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Essential Libraries...\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "print('Importing Essential Libraries...')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "\n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing classes from sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the sklean classes\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_Regression  = LogisticRegression(max_iter=10000)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data.....\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "print('Loading the data.....')\n",
    "df = pd.read_csv('./Data/train_data.csv')\n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The first 5 rows are: ')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The data has the following information: ')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The shape of the dataframe is:- Rows: ',df.shape[0],' Columns: ',df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization and Data Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the given data how many loans replayed and defaulted loans.\n",
    "# fig, ax = plt.subplots(figsize=(7,5))\n",
    "# sns.countplot(x = 'TARGET',data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Who is the highest borrower? Male or Female?\n",
    "# fig, ax = plt.subplots(figsize=(10,7))\n",
    "# sns.countplot(x='CODE_GENDER',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #How is the distribution of target labels? - Did most people return on time ?\n",
    "# fig, ax = plt.subplots(figsize=(10,7))\n",
    "# sns.countplot(x ='TARGET',data=df, hue='TARGET',palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Whether is it Female who has more difficulties or is it Male in repaying the loan?\n",
    "# fig, ax = plt.subplots(figsize=(10,7))\n",
    "# sns.countplot(x='TARGET',hue='CODE_GENDER',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Who owns most number of the cars? M or F?\n",
    "# fig, ax = plt.subplots(figsize=(10,7))\n",
    "# sns.countplot(x='CODE_GENDER', hue='FLAG_OWN_CAR', data=df,palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'TARGET']\n",
      "['SK_ID_CURR', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'TOTALAREA_MODE', 'DAYS_LAST_PHONE_CHANGE']\n"
     ]
    }
   ],
   "source": [
    "l1 = []\n",
    "l2 = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].nunique() < 100:\n",
    "        l1.append(i)\n",
    "    else:\n",
    "        l2.append(i)\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Drawing Histogram!!!')\n",
    "# for h in l2:\n",
    "#     fig, ax = plt.subplots(1,1, figsize=(15, 6))\n",
    "#     sns.histplot(df[h], palette='Blues_r')\n",
    "#     fig.text(0.1, 0.95, f'{h}', fontsize=16, fontweight='bold', fontfamily='serif')\n",
    "#     plt.xlabel('value ', fontsize=10)\n",
    "#     plt.ylabel('count',fontsize=10)\n",
    "#     plt.yticks(fontsize=13)\n",
    "#     plt.box(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING THE ENTIRE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINDING THE COLUMNS THAT HAVE NULL VALUES OF MORE THAN 50%\n",
    "### DROP THEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OWN_CAR_AGE      121633 65.92360140049645\n",
      "EXT_SOURCE_1      104074 56.40683771801459\n",
      "APARTMENTS_AVG      93575 50.7165078642429\n",
      "BASEMENTAREA_AVG      107975 58.521132104105014\n",
      "YEARS_BUILD_AVG      122757 66.53279568144126\n",
      "COMMONAREA_AVG      128971 69.90070783605952\n",
      "ELEVATORS_AVG      98320 53.28823994883635\n",
      "ENTRANCES_AVG      92807 50.30026123811692\n",
      "FLOORSMIN_AVG      125244 67.88071932620078\n",
      "LANDAREA_AVG      109543 59.37096896577889\n",
      "LIVINGAPARTMENTS_AVG      126212 68.40536351121372\n",
      "LIVINGAREA_AVG      92534 50.1522985702362\n",
      "NONLIVINGAPARTMENTS_AVG      128146 69.45356790565076\n",
      "NONLIVINGAREA_AVG      101788 55.16785361993648\n",
      "APARTMENTS_MODE      93575 50.7165078642429\n",
      "BASEMENTAREA_MODE      107975 58.521132104105014\n",
      "YEARS_BUILD_MODE      122757 66.53279568144126\n",
      "COMMONAREA_MODE      128971 69.90070783605952\n",
      "ELEVATORS_MODE      98320 53.28823994883635\n",
      "ENTRANCES_MODE      92807 50.30026123811692\n",
      "FLOORSMIN_MODE      125244 67.88071932620078\n",
      "LANDAREA_MODE      109543 59.37096896577889\n",
      "LIVINGAPARTMENTS_MODE      126212 68.40536351121372\n",
      "LIVINGAREA_MODE      92534 50.1522985702362\n",
      "NONLIVINGAPARTMENTS_MODE      128146 69.45356790565076\n",
      "NONLIVINGAREA_MODE      101788 55.16785361993648\n",
      "APARTMENTS_MEDI      93575 50.7165078642429\n",
      "BASEMENTAREA_MEDI      107975 58.521132104105014\n",
      "YEARS_BUILD_MEDI      122757 66.53279568144126\n",
      "COMMONAREA_MEDI      128971 69.90070783605952\n",
      "ELEVATORS_MEDI      98320 53.28823994883635\n",
      "ENTRANCES_MEDI      92807 50.30026123811692\n",
      "FLOORSMIN_MEDI      125244 67.88071932620078\n",
      "LANDAREA_MEDI      109543 59.37096896577889\n",
      "LIVINGAPARTMENTS_MEDI      126212 68.40536351121372\n",
      "LIVINGAREA_MEDI      92534 50.1522985702362\n",
      "NONLIVINGAPARTMENTS_MEDI      128146 69.45356790565076\n",
      "NONLIVINGAREA_MEDI      101788 55.16785361993648\n",
      "FONDKAPREMONT_MODE      126254 68.42812699858\n",
      "HOUSETYPE_MODE      92482 50.12411520492559\n",
      "WALLSMATERIAL_MODE      93721 50.79563808223039\n"
     ]
    }
   ],
   "source": [
    "to_drop=[] #this is a list that stores the names of cols having more than 50% nulls\n",
    "for features in df.columns:\n",
    "    percentage = (df[features].isna().sum()/df.shape[0]) *100\n",
    "    if df[features].isna().sum() > 0 and percentage > 50.0:\n",
    "        to_drop.append(features)\n",
    "        print(features,'    ' ,df[features].isna().sum(), percentage)\n",
    "        df.drop(features,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The shape of the dataframe after deleting the columns are:- Rows: ',df.shape[0],' Columns: ',df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the SK_ID_CURR column as it a primary key and has no actual use here.\n",
    "df.drop('SK_ID_CURR',axis= 1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Duplicate Rows present here are:  0\n"
     ]
    }
   ],
   "source": [
    "#Check for duplicate data rows\n",
    "countDuplicateRows = df[df.duplicated(subset = None, keep= False)].shape[0]\n",
    "print('The number of Duplicate Rows present here are: ',countDuplicateRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAKING CARE OF NULL VALUES IN THE REMAINING COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMT_ANNUITY     6    24939.0    27114.45580487805\n",
      "AMT_GOODS_PRICE     167    450000.0    538692.5954138841\n",
      "CNT_FAM_MEMBERS     1    2.0    2.1527058887293027\n",
      "EXT_SOURCE_2     413    0.565999028    0.5146160060113203\n",
      "EXT_SOURCE_3     36656    0.53527625    0.5108943568087724\n",
      "YEARS_BEGINEXPLUATATION_AVG     89900    0.9816    0.9777946810984505\n",
      "FLOORSMAX_AVG     91726    0.1667    0.22596766544513902\n",
      "YEARS_BEGINEXPLUATATION_MODE     89900    0.9816    0.9770830296175718\n",
      "FLOORSMAX_MODE     91726    0.1667    0.22189942013364952\n",
      "YEARS_BEGINEXPLUATATION_MEDI     89900    0.9816    0.9778308119992389\n",
      "FLOORSMAX_MEDI     91726    0.1667    0.2255433229144212\n",
      "TOTALAREA_MODE     88948    0.0687    0.10221478473806483\n",
      "OBS_30_CNT_SOCIAL_CIRCLE     639    0.0    1.4261014755230683\n",
      "DEF_30_CNT_SOCIAL_CIRCLE     639    0.0    0.14431083337412368\n",
      "OBS_60_CNT_SOCIAL_CIRCLE     639    0.0    1.4092469012927822\n",
      "DEF_60_CNT_SOCIAL_CIRCLE     639    0.0    0.10060532885183311\n",
      "DAYS_LAST_PHONE_CHANGE     1    -756.0    -961.9845912034904\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR     24998    0.0    0.006338240088271435\n",
      "AMT_REQ_CREDIT_BUREAU_DAY     24998    0.0    0.007335055295032224\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK     24998    0.0    0.03439952855029215\n",
      "AMT_REQ_CREDIT_BUREAU_MON     24998    0.0    0.26724678386037065\n",
      "AMT_REQ_CREDIT_BUREAU_QRT     24998    0.0    0.26677031873009505\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR     24998    1.0    1.897503573488477\n",
      "\n",
      "\n",
      "Total such columns are 23\n"
     ]
    }
   ],
   "source": [
    "#We have deleted the columns with >50% Null values, but there are some columns with null values. \n",
    "#Handling them here.\n",
    "#Checking the remaining columns with null values and their corresponding median and mean values and store them in a list.\n",
    "\n",
    "count = 0\n",
    "featureList = []\n",
    "for features in df.columns:\n",
    "    if df[features].isna().sum() > 0 and df[features].dtype != object:\n",
    "        featureList.append(features)\n",
    "        print(features, '   ', df[features].isna().sum(),'  ',df[features].median(), '  ',df[features].mean() )\n",
    "        count += 1\n",
    "print('\\n\\nTotal such columns are',count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the List that we got here.(i.e names of features having some null values)\n",
    "print(featureList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMT_ANNUITY', 'AMT_GOODS_PRICE', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'YEARS_BEGINEXPLUATATION_AVG', 'FLOORSMAX_AVG', 'YEARS_BEGINEXPLUATATION_MODE', 'FLOORSMAX_MODE', 'YEARS_BEGINEXPLUATATION_MEDI', 'FLOORSMAX_MEDI', 'TOTALAREA_MODE', 'DAYS_LAST_PHONE_CHANGE', 'AMT_REQ_CREDIT_BUREAU_WEEK']\n"
     ]
    }
   ],
   "source": [
    "#From the list obtained in the previous cell, we have to pick out those who have integer numbers and then fill the rest i.e float values. \n",
    "#ones with median values of the entire column.\n",
    "\n",
    "\n",
    "modifiedListFeaturesWithWholeNumbers = ['CNT_FAM_MEMBERS','OBS_30_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE','AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']\n",
    "\n",
    "s = set()\n",
    "for i in modifiedListFeaturesWithWholeNumbers:\n",
    "    s.add(i)\n",
    "\n",
    "#Contains only the list with floating point values.\n",
    "newList = []\n",
    "for i in featureList:\n",
    "    if i not in s:\n",
    "       newList.append(i) \n",
    "print(newList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the null values in columns with floating point values and fill it out with median of the entire column.\n",
    "for i in newList:\n",
    "    df[i] = df[i].fillna(df[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME_TYPE_SUITE object\n",
      "OCCUPATION_TYPE object\n",
      "CNT_FAM_MEMBERS float64\n",
      "EMERGENCYSTATE_MODE object\n",
      "OBS_30_CNT_SOCIAL_CIRCLE float64\n",
      "DEF_30_CNT_SOCIAL_CIRCLE float64\n",
      "OBS_60_CNT_SOCIAL_CIRCLE float64\n",
      "DEF_60_CNT_SOCIAL_CIRCLE float64\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR float64\n",
      "AMT_REQ_CREDIT_BUREAU_DAY float64\n",
      "AMT_REQ_CREDIT_BUREAU_MON float64\n",
      "AMT_REQ_CREDIT_BUREAU_QRT float64\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR float64\n"
     ]
    }
   ],
   "source": [
    "# The left out columns of the categorical type and integer numbers.\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].isna().sum() > 0:\n",
    "        print(i,df[i].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill the elements in modifiedListFeaturesWithWholeNumbers with integers.\n",
    "for i in modifiedListFeaturesWithWholeNumbers:\n",
    "    if df[i].dtype != object:\n",
    "        df[i] = df[i].fillna(int(df[i].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME_TYPE_SUITE object 770\n",
      "OCCUPATION_TYPE object 57867\n",
      "EMERGENCYSTATE_MODE object 87336\n"
     ]
    }
   ],
   "source": [
    "#The columns left out with still null values. These are mainly of type string/object.\n",
    "categoricalData = []\n",
    "for i in df.columns:\n",
    "    if df[i].isna().sum() > 0:\n",
    "        print(i,df[i].dtype,df[i].isna().sum())\n",
    "        categoricalData.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the Columns that have values that don't make any sense.\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(i,'   ',df[i].unique(),'  ',df[i].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'M' 'XNA']\n",
      "['Family' 'Unaccompanied' 'Spouse, partner' 'Children' nan 'Other_A'\n",
      " 'Other_B' 'Group of people']\n",
      "['Married' 'Civil marriage' 'Single / not married' 'Separated' 'Widow'\n",
      " 'Unknown']\n",
      "['Business Entity Type 3' 'Transport: type 4' 'Other' 'Self-employed'\n",
      " 'XNA' 'Trade: type 7' 'Kindergarten' 'Transport: type 2' 'Restaurant'\n",
      " 'Insurance' 'Government' 'Medicine' 'Bank' 'Industry: type 3' 'Military'\n",
      " 'Security' 'Realtor' 'Industry: type 9' 'Culture'\n",
      " 'Business Entity Type 2' 'Legal Services' 'Emergency' 'Postal'\n",
      " 'Business Entity Type 1' 'Electricity' 'Housing' 'Trade: type 3' 'School'\n",
      " 'Agriculture' 'Hotel' 'University' 'Construction' 'Police'\n",
      " 'Industry: type 7' 'Security Ministries' 'Transport: type 3' 'Services'\n",
      " 'Trade: type 2' 'Trade: type 6' 'Industry: type 11' 'Cleaning'\n",
      " 'Industry: type 2' 'Industry: type 5' 'Religion' 'Trade: type 1' 'Mobile'\n",
      " 'Industry: type 1' 'Industry: type 12' 'Industry: type 4'\n",
      " 'Transport: type 1' 'Advertising' 'Telecom' 'Trade: type 5'\n",
      " 'Industry: type 10' 'Industry: type 6' 'Trade: type 4'\n",
      " 'Industry: type 13' 'Industry: type 8']\n"
     ]
    }
   ],
   "source": [
    "# These columns have values that don't make any sense.\n",
    "\n",
    "print(df['CODE_GENDER'].unique())               # XNA\n",
    "print(df['NAME_TYPE_SUITE'].unique())           # Other_A, Other_B\n",
    "print(df['NAME_FAMILY_STATUS'].unique())        # Unknown\n",
    "print(df['ORGANIZATION_TYPE'].unique())         # XNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing these Absurd values with NaN values.\n",
    "\n",
    "df['CODE_GENDER'] = df['CODE_GENDER'].replace('XNA',np.nan)\n",
    "df['NAME_TYPE_SUITE'] = df['NAME_TYPE_SUITE'].replace('Other_A',np.nan)\n",
    "df['NAME_TYPE_SUITE'] = df['NAME_TYPE_SUITE'].replace('Other_B',np.nan)\n",
    "df['NAME_FAMILY_STATUS'] = df['NAME_FAMILY_STATUS'].replace('Unknown',np.nan)\n",
    "df['ORGANIZATION_TYPE'] = df['ORGANIZATION_TYPE'].replace('XNA',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_CONTRACT_TYPE            0\n",
       "CODE_GENDER                   0\n",
       "FLAG_OWN_CAR                  0\n",
       "FLAG_OWN_REALTY               0\n",
       "CNT_CHILDREN                  0\n",
       "                             ..\n",
       "AMT_REQ_CREDIT_BUREAU_WEEK    0\n",
       "AMT_REQ_CREDIT_BUREAU_MON     0\n",
       "AMT_REQ_CREDIT_BUREAU_QRT     0\n",
       "AMT_REQ_CREDIT_BUREAU_YEAR    0\n",
       "TARGET                        0\n",
       "Length: 80, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Handling the nulls in categorical data.\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        df[i] = df[i].fillna(df[i].mode()[0])\n",
    "\n",
    "#NULLS HAVE BEEN REMOVED.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DAYS_LAST_PHONE_CHANGE      #contians negative date values\n",
    "\n",
    "#Need to handle this also. Can't understand what this -ve value means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LABEL ENCODING FOR CATEGORICAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Label Encoding....\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "#Label Encoding all the categorical object using Label Encoder.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "print('Applying Label Encoding....')\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        df[i] = label_encoder.fit_transform(df[i])\n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('TARGET',axis = 1)\n",
    "y = df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    169611\n",
       "1     14895\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HANDLING THE IMBALANCED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/.local/lib/python3.10/site-packages/imblearn/utils/_validation.py:586: FutureWarning: Pass sampling_strategy=0.75 as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit {} Counter({0: 169611, 1: 14895})\n",
      "The number of classes after fit {} Counter({0: 169611, 1: 124176})\n",
      "Shape before sampling (184506, 79) (184506,)\n",
      "Shape after sampling (293787, 79) (293787,)\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import KMeansSMOTE,SMOTE,ADASYN,SVMSMOTE\n",
    "ksmote = ADASYN(0.75,random_state=42)\n",
    "X_res,Y_res = ksmote.fit_resample(x,y)\n",
    "\n",
    "\n",
    "print(\"The number of classes before fit {}\",format(Counter(y)))\n",
    "print(\"The number of classes after fit {}\",format(Counter(Y_res)))\n",
    "\n",
    "print('Shape before sampling',x.shape,y.shape)\n",
    "print('Shape after sampling',X_res.shape,Y_res.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN TEST SPLIT THE ENTIRE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data shape:   (205650, 79) (205650,)\n",
      "Testing  Data shape:   (88137, 79) (88137,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_Train,X_Test,Y_Train,Y_Test = train_test_split(X_res,Y_res,train_size= 0.7,shuffle= True,random_state=42)\n",
    "print(\"Training Data shape:  \",X_Train.shape,Y_Train.shape)\n",
    "print(\"Testing  Data shape:  \",X_Test.shape,Y_Test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the correlation of the inpendent features with the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  0.0 Feature Name:  FLAG_DOCUMENT_12\n",
      "1\n",
      "['FLAG_DOCUMENT_12']\n",
      "Dropping Columns....\n",
      "(205650, 79)\n",
      "(205650, 78)\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "abs_corr_matrix = X_Train.corr().abs()                               #absoulte value correlation matrix\n",
    "corr_target_checker = abs_corr_matrix[len(abs_corr_matrix)-1:]  #corr of target\n",
    "corr_target_checker\n",
    "to_drop=[]                                                      # A list that stores col names of low corr\n",
    "count = 0\n",
    "for i in corr_target_checker.columns:\n",
    "    if corr_target_checker[i].sum() < 0.0005:\n",
    "        print('Value: ',corr_target_checker[i].sum(),'Feature Name: ',i)\n",
    "        to_drop.append(i)\n",
    "        count += 1\n",
    "print(count)\n",
    "print(to_drop)\n",
    "\n",
    "print('Dropping Columns....')\n",
    "print(X_Train.shape)\n",
    "X_Train.drop(to_drop,axis= 1,inplace= True)\n",
    "print(X_Train.shape)\n",
    "print('Done!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE SELECTION USING RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "# For Random Forest Classifier\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators= 100,criterion= 'entropy'))\n",
    "sel.fit(X_Train,Y_Train)\n",
    "\n",
    "\n",
    "# # For Decision Tree Classifier\n",
    "# sel = SelectFromModel(ExtraTreesClassifier(n_estimators= 100,criterion= 'gini'))\n",
    "# sel.fit(X_Train,Y_Train)\n",
    "\n",
    "\n",
    "selected_features = X_Train.columns[(sel.get_support())]\n",
    "print(\"The Number of features selected are: \",len(selected_features))\n",
    "print(\"The features selected are: \",selected_features)\n",
    "\n",
    "# pd.series(sel.estimator_,feature_importa).hist()\n",
    "\n",
    "#Dropping the columns that are not present in the selected_features list\n",
    "\n",
    "for i in X_Train.columns:\n",
    "    if i not in selected_features:\n",
    "        X_Train.drop(i,axis= 1,inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the selected_features for doing EDA on the Test Data.\n",
    "%store selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_Train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Outliers Using IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plotting BoxPlot of the left out columns to check if they have any outliers.\n",
    "# print('Before Removing Outliers')\n",
    "# count = 0\n",
    "# for i in X_Train.columns:\n",
    "#     fig = plt.figure(figsize=(7,4))\n",
    "#     plt.boxplot(X_Train[i])\n",
    "#     plt.suptitle(i)\n",
    "#     plt.show()\n",
    "#     count += 1\n",
    "\n",
    "# print('Total Boxplots printed are: ',count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now find the outliers using IQR Method and remove them from the entire data X_Train\n",
    "def drop_outliers_IQR(df,feature):\n",
    "    iqr = 1.5*( np.percentile(df[feature],75) - np.percentile(df[feature],25)   )\n",
    "    # df.drop( df[df[feature] > (iqr + np.percentile(df[feature],75))].index,inplace= True )\n",
    "    # df.drop( df[df[feature] < (np.percentile(df[feature],25) - iqr)].index,inplace= True )\n",
    "\n",
    "    df.loc[df[feature] > (iqr + np.percentile(df[feature],75))] = df[feature].mean()\n",
    "    df.loc[df[feature] < (np.percentile(df[feature],25) - iqr)] = df[feature].mean()\n",
    "    #df[feature] = df[feature].fillna(df[feature].mean())\n",
    "   \n",
    "\n",
    "for i in X_Train.columns:\n",
    "    drop_outliers_IQR(X_Train,i)\n",
    "\n",
    "\n",
    "# drop_outliers_IQR(X_Train,'CNT_CHILDREN')\n",
    "# drop_outliers_IQR(X_Train,'NAME_FAMILY_STATUS')\n",
    "# drop_outliers_IQR(X_Train,'NAME_HOUSING_TYPE')\n",
    "# drop_outliers_IQR(X_Train,'OCCUPATION_TYPE')\n",
    "# drop_outliers_IQR(X_Train,'CNT_FAM_MEMBERS')\n",
    "# drop_outliers_IQR(X_Train,'HOUR_APPR_PROCESS_START')\n",
    "# drop_outliers_IQR(X_Train,'EXT_SOURCE_1')\n",
    "# drop_outliers_IQR(X_Train,'EXT_SOURCE_3')\n",
    "# drop_outliers_IQR(X_Train, 'ENTRANCES_MODE')\n",
    "# drop_outliers_IQR(X_Train,'FLOORSMAX_MODE')\n",
    "# drop_outliers_IQR(X_Train,'FLOORSMAX_MEDI')\n",
    "# drop_outliers_IQR(X_Train,'WALLSMATERIAL_MODE')\n",
    "# drop_outliers_IQR(X_Train,'DEF_30_CNT_SOCIAL_CIRCLE')\n",
    "# drop_outliers_IQR(X_Train,'OBS_60_CNT_SOCIAL_CIRCLE')\n",
    "# drop_outliers_IQR(X_Train,'DEF_60_CNT_SOCIAL_CIRCLE')\n",
    "# drop_outliers_IQR(X_Train,'AMT_REQ_CREDIT_BUREAU_DAY')\n",
    "# drop_outliers_IQR(X_Train,'AMT_REQ_CREDIT_BUREAU_WEEK')\n",
    "# drop_outliers_IQR(X_Train,'AMT_REQ_CREDIT_BUREAU_QRT')\n",
    "# drop_outliers_IQR(X_Train,'AMT_REQ_CREDIT_BUREAU_YEAR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plotting BoxPlot of the left out columns after removal of outliers.\n",
    "# print('After Removing Outliers')\n",
    "# count = 0\n",
    "# for i in X_Train.columns:\n",
    "#     fig = plt.figure(figsize=(7,4))\n",
    "#     plt.boxplot(X_Train[i])\n",
    "#     plt.suptitle(i)\n",
    "#     plt.show()\n",
    "#     count += 1\n",
    "\n",
    "# print('Total Boxplots printed are: ',count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205650, 78) (205650,)\n"
     ]
    }
   ],
   "source": [
    "print(X_Train.shape,Y_Train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REMOVING THE COLUMNS FROM THE TEST DATA PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_Test.columns:\n",
    "    if i not in selected_features:\n",
    "        X_Test.drop(i,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCALING THE ENTIRE DATA USING STANDARD SCALAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Applying Scaling on the training data only for the features...')\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_Train)\n",
    "X_Train = scaler.transform(X_Train)\n",
    "print('Done!!')\n",
    "#Pass this scaled data as input to the Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/.local/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- AMT_REQ_CREDIT_BUREAU_DAY\n",
      "- AMT_REQ_CREDIT_BUREAU_HOUR\n",
      "- AMT_REQ_CREDIT_BUREAU_MON\n",
      "- AMT_REQ_CREDIT_BUREAU_QRT\n",
      "- AMT_REQ_CREDIT_BUREAU_WEEK\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 24 features, but LogisticRegression is expecting 78 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [73], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m logistic_Regression\u001b[39m.\u001b[39mfit(X_Train,Y_Train)\n\u001b[0;32m----> 2\u001b[0m Y_Pred \u001b[39m=\u001b[39m logistic_Regression\u001b[39m.\u001b[39;49mpredict(X_Test)\n\u001b[1;32m      4\u001b[0m lacc \u001b[39m=\u001b[39m accuracy_score(Y_Pred,Y_Test)\n\u001b[1;32m      5\u001b[0m lf1 \u001b[39m=\u001b[39m f1_score(Y_Pred,Y_Test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:447\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    434\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    449\u001b[0m         indices \u001b[39m=\u001b[39m (scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:429\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    427\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 429\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    430\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    431\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mravel() \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 24 features, but LogisticRegression is expecting 78 features as input."
     ]
    }
   ],
   "source": [
    "logistic_Regression.fit(X_Train,Y_Train)\n",
    "Y_Pred = logistic_Regression.predict(X_Test)\n",
    "\n",
    "lacc = accuracy_score(Y_Pred,Y_Test)\n",
    "lf1 = f1_score(Y_Pred,Y_Test)\n",
    "lauc_score = roc_auc_score(Y_Pred,Y_Test)\n",
    "print('The accuracy of the model on training data is: ')\n",
    "\n",
    "print('The accuracy  is: ',lacc*100,'%')\n",
    "print('The value of f1_score is: ',lf1*100,'%')\n",
    "print('The value of Roc AUC Score is: ',lauc_score*100,'%')\n",
    "\n",
    "print(\"The confusion matrix is: \\n\\n\",confusion_matrix(Y_Test,Y_Pred))\n",
    "print(\"The classification report is: \\n\\n\",classification_report(Y_Test,Y_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING K NEAREST NEIGHBOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# for k in range(1, 100, 5):\n",
    "#     k = k + 1\n",
    "#     knn = KNeighborsClassifier(n_neighbors = k).fit(X_Train,Y_Train)\n",
    "#     acc = knn.score(X_Test,Y_Test)\n",
    "#     print(\"Accuracy for k = \",k,\" is: \",acc)\n",
    "\n",
    "# Here we are selecting which is the best n value for the KNN algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/.local/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- AMT_REQ_CREDIT_BUREAU_DAY\n",
      "- AMT_REQ_CREDIT_BUREAU_HOUR\n",
      "- AMT_REQ_CREDIT_BUREAU_MON\n",
      "- AMT_REQ_CREDIT_BUREAU_QRT\n",
      "- AMT_REQ_CREDIT_BUREAU_WEEK\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 24 features, but KNeighborsClassifier is expecting 78 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [72], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m KNeighborsClassifier\n\u001b[1;32m      2\u001b[0m knn \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mfit(X_Train,Y_Train)\n\u001b[0;32m----> 3\u001b[0m Y_Pred \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mpredict(X_Test)\n\u001b[1;32m      4\u001b[0m kacc \u001b[39m=\u001b[39m accuracy_score(Y_Pred,Y_Test)\n\u001b[1;32m      5\u001b[0m kf1 \u001b[39m=\u001b[39m f1_score(Y_Pred,Y_Test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:226\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m    Class labels for each data sample.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    224\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    227\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_base.py:745\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    743\u001b[0m         X \u001b[39m=\u001b[39m _check_precomputed(X)\n\u001b[1;32m    744\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    747\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 24 features, but KNeighborsClassifier is expecting 78 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors= 2).fit(X_Train,Y_Train)\n",
    "Y_Pred = knn.predict(X_Test)\n",
    "kacc = accuracy_score(Y_Pred,Y_Test)\n",
    "kf1 = f1_score(Y_Pred,Y_Test)\n",
    "kauc_score = roc_auc_score(Y_Pred,Y_Test)\n",
    "\n",
    "\n",
    "print('The accuracy of the model on Data is: ')\n",
    "\n",
    "print('The accuracy  is: ',kacc*100,'%')\n",
    "print('The value of f1_score is: ',kf1*100,'%')\n",
    "print('The value of Roc AUC Score is: ',kauc_score*100,'%')\n",
    "\n",
    "print(\"The confusion matrix is: \\n\\n\",confusion_matrix(Y_Test,Y_Pred))\n",
    "print(\"The classification report is: \\n\\n\",classification_report(Y_Test,Y_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING SUPPORT VECTOR MACHINES(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# svc = SVC()\n",
    "# svc.fit(X_Train,Y_Train)\n",
    "\n",
    "# Y_Pred = svc.predict(X_Test)\n",
    "# acc = accuracy_score(Y_Pred,Y_Test)\n",
    "# f1 = f1_score(Y_Pred,Y_Test)\n",
    "# auc_score = roc_auc_score(Y_Pred,Y_Test)\n",
    "\n",
    "\n",
    "# print('The accuracy of the model on Data is: ')\n",
    "\n",
    "# print('The accuracy  is: ',acc*100,'%')\n",
    "# print('The value of f1_score is: ',f1*100,'%')\n",
    "# print('The value of Roc AUC Score is: ',auc_score*100,'%')\n",
    "\n",
    "# print(\"The confusion matrix is: \\n\\n\",confusion_matrix(Y_Test,Y_Pred))\n",
    "# print(\"The classification report is: \\n\\n\",classification_report(Y_Test,Y_Pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### applying Grid Search CV to get the best hyperparameters for the XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = XGBClassifier(random_state = 30)\n",
    "# search_space = {\n",
    "#     \"n_estimators\" :   [100,200],\n",
    "#     \"max_depth\" :      [3,6,7],\n",
    "#     \"gamma\" :          [0.01,0.1],\n",
    "#     \"learning_rate\" :  [0.001,0.01,0.1,1]\n",
    "# }\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# GS = GridSearchCV(\n",
    "#     estimator= xgb_model,\n",
    "#     param_grid= search_space,\n",
    "#     scoring= [\"roc_auc\",\"roc_auc_ovr\",\"roc_auc_ovo\",\"f1\",\"f1_micro\",\"f1_macro\",\"accuracy\"],\n",
    "#     refit= \"roc_auc\",\n",
    "#     cv= 5,\n",
    "#     verbose= 4\n",
    "# )\n",
    "\n",
    "# GS.fit(X_Train,Y_Train)\n",
    "\n",
    "# print(\"The best estimator is: \",GS.best_estimator_)\n",
    "# print(\"The best parameter is: \",GS.best_params_)\n",
    "# print(\"The best AUC_ROC score is: \",GS.best_score_)\n",
    "# df_XGBoost = pd.DataFrame(GS.cv_results_)\n",
    "# df_XGBoost = df_XGBoost.sort_values(\"rank_test_roc_auc\")\n",
    "# df_XGBoost.to_csv('./Test_Output/XGBoost_GridSearchCV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_XGB = XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
    "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
    "              early_stopping_rounds=None, enable_categorical=False,\n",
    "              eval_metric=None, feature_types=None, gamma=0.1, gpu_id=-1,\n",
    "              grow_policy='depthwise', importance_type=None,\n",
    "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
    "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
    "              max_depth=7, max_leaves=0, min_child_weight=1,\n",
    "              monotone_constraints='()', n_estimators=200, n_jobs=0,\n",
    "              num_parallel_tree=1, predictor='auto', random_state=30)\n",
    "\n",
    "model_XGB.fit(X_Train,Y_Train)\n",
    "\n",
    "Y_Pred = model_XGB.predict(X_Test)\n",
    "xacc = accuracy_score(Y_Pred,Y_Test)\n",
    "xf1 = f1_score(Y_Pred,Y_Test)\n",
    "#xauc_score = roc_auc_score(Y_Pred,Y_Test)\n",
    "\n",
    "\n",
    "print('The accuracy of the model on Data is: ')\n",
    "\n",
    "print('The accuracy  is: ',xacc*100,'%')\n",
    "print('The value of f1_score is: ',xf1*100,'%')\n",
    "#print('The value of Roc AUC Score is: ',xauc_score*100,'%')\n",
    "\n",
    "print(\"The confusion matrix is: \\n\\n\",confusion_matrix(Y_Test,Y_Pred))\n",
    "print(\"The classification report is: \\n\\n\",classification_report(Y_Test,Y_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING DECISION TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_Train,Y_Train)\n",
    "Y_Pred = dt.predict(X_Test)\n",
    "dacc = accuracy_score(Y_Pred,Y_Test)\n",
    "df1 = f1_score(Y_Pred,Y_Test)\n",
    "dauc_score = roc_auc_score(Y_Pred,Y_Test)\n",
    "\n",
    "\n",
    "print('The accuracy of the model on Data is: ')\n",
    "\n",
    "print('The accuracy  is: ',dacc*100,'%')\n",
    "print('The value of f1_score is: ',df1*100,'%')\n",
    "print('The value of Roc AUC Score is: ',dauc_score*100,'%')\n",
    "\n",
    "print(\"The confusion matrix is: \\n\\n\",confusion_matrix(Y_Test,Y_Pred))\n",
    "print(\"The classification report is: \\n\\n\",classification_report(Y_Test,Y_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier().fit(X_Train,Y_Train)\n",
    "Y_Pred = rf.predict(X_Test)\n",
    "racc = accuracy_score(Y_Pred,Y_Test)\n",
    "rf1 = f1_score(Y_Pred,Y_Test)\n",
    "rauc_score = roc_auc_score(Y_Pred,Y_Test)\n",
    "\n",
    "\n",
    "print('The accuracy of the model on Data is: ')\n",
    "\n",
    "print('The accuracy  is: ',racc*100,'%')\n",
    "print('The value of f1_score is: ',rf1*100,'%')\n",
    "print('The value of Roc AUC Score is: ',rauc_score*100,'%')\n",
    "\n",
    "print(\"The confusion matrix is: \\n\\n\",confusion_matrix(Y_Test,Y_Pred))\n",
    "print(\"The classification report is: \\n\\n\",classification_report(Y_Test,Y_Pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING VARIOUS NAIVE BAYES ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GAUSSIAN NAIVE BAYES\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_Train,Y_Train)\n",
    "Y_Pred = model.predict(X_Test)\n",
    "gnbacc = accuracy_score(Y_Pred,Y_Test)\n",
    "gnbf1 = f1_score(Y_Pred,Y_Test)\n",
    "gnbauc_score = roc_auc_score(Y_Pred,Y_Test)\n",
    "\n",
    "\n",
    "print('The accuracy of the model on Data is: ')\n",
    "\n",
    "print('The accuracy  is: ',gnbacc*100,'%')\n",
    "print('The value of f1_score is: ',gnbf1*100,'%')\n",
    "print('The value of Roc AUC Score is: ',gnbauc_score*100,'%')\n",
    "\n",
    "print(\"The confusion matrix is: \\n\\n\",confusion_matrix(Y_Test,Y_Pred))\n",
    "print(\"The classification report is: \\n\\n\",classification_report(Y_Test,Y_Pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BERNOULLI NAIVE BAYES\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(X_Train,Y_Train)\n",
    "Y_Pred = model.predict(X_Test)\n",
    "bnbacc = accuracy_score(Y_Pred,Y_Test)\n",
    "bnbf1 = f1_score(Y_Pred,Y_Test)\n",
    "bnbauc_score = roc_auc_score(Y_Pred,Y_Test)\n",
    "\n",
    "\n",
    "print('The accuracy of the model on Data is: ')\n",
    "\n",
    "print('The accuracy  is: ',bnbacc*100,'%')\n",
    "print('The value of f1_score is: ',bnbf1*100,'%')\n",
    "print('The value of Roc AUC Score is: ',bnbauc_score*100,'%')\n",
    "\n",
    "print(\"The confusion matrix is: \\n\\n\",confusion_matrix(Y_Test,Y_Pred))\n",
    "print(\"The classification report is: \\n\\n\",classification_report(Y_Test,Y_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARING ALL THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "t = PrettyTable(['ALGO','ACCURACY SCORE','F1 SCORE','ROC-AUC SCORE'])\n",
    "t.add_row(['Logistic Regression',round(lacc,2),round(lf1,2),round(lauc_score,2)])\n",
    "t.add_row(['KNN',round(kacc,2),round(kf1,2),round(kauc_score,2)])\n",
    "t.add_row(['XG Boost',round(xacc,2),round(xf1,2),round(xauc_score,2)])\n",
    "t.add_row(['Decision Trees',round(dacc,2),round(df1,2),round(dauc_score,2)])\n",
    "t.add_row(['Random Forest',round(racc,2),round(rf1,2),round(rauc_score,2)])\n",
    "t.add_row(['Gaussian NB', round(gnbacc,2),round(gnbf1,2),round(gnbauc_score,2)])\n",
    "t.add_row(['Bernoulli NB',round(bnbacc,2),round(bnbf1,2),round(bnbauc_score,2)])\n",
    "\n",
    "\n",
    "print(t)\n",
    "\n",
    "#Looking at the values it can be concluded that the best algo is XGBOOST!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.array([\"Logistic Regression\",\"\\nKNN\",\"XG Boost\",\"\\nDecision Trees\",\"Random Forest\",\"\\nGaussian NB\",\"Bernoulli NB\"])\n",
    "y_axis = np.array([lauc_score,kauc_score,xauc_score,dauc_score,rauc_score,gnbauc_score,bnbauc_score])\n",
    "plt.bar(x_axis,y_axis,align= 'center',width= 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING THE TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the test data.....')\n",
    "df_test = pd.read_csv('./Data/test_data.csv')\n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = df_test['SK_ID_CURR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the unnecessary columns from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the columns that are not in X_Train\n",
    "for i in df_test.columns:\n",
    "    if i not in selected_features:\n",
    "        df_test.drop(i,axis=1,inplace= True)\n",
    "\n",
    "print(df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the Unnecessary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_test.columns:\n",
    "    if df_test[i].dtype == 'object':\n",
    "        print(\"Column: \",i,\" Values: \",df_test[i].unique())\n",
    "\n",
    "df_test['ORGANIZATION_TYPE'] = df['ORGANIZATION_TYPE'].replace('XNA',np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the NULL Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_test.columns:\n",
    "    if df_test[i].dtype == 'object':\n",
    "        df_test[i] = df_test[i].fillna(df_test[i].mode()[0])\n",
    "    if df_test[i].dtype == 'int64':\n",
    "        df_test[i] = df_test[i].fillna(int(df_test[i].mean()))\n",
    "    if df_test[i].dtype == 'float64':\n",
    "        df_test[i] = df_test[i].fillna(df_test[i].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segregating the categorical and non-categorical data\n",
    "cat = []\n",
    "for i in df_test.columns:\n",
    "    if df_test[i].dtype == 'object':\n",
    "        cat.append(i)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "label_encoder_test = preprocessing.LabelEncoder()\n",
    "\n",
    "print('Applying Label Encoding to only Categorical Data....')\n",
    "for i in cat:\n",
    "    df_test[i] = label_encoder_test.fit_transform(df_test[i])\n",
    "\n",
    "print('Done!!!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply OutLier Removing from non categorical columns in Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers_IQR(df,feature):\n",
    "    iqr = 1.5*( np.percentile(df[feature],75) - np.percentile(df[feature],25)   )\n",
    "    # df.drop( df[df[feature] > (iqr + np.percentile(df[feature],75))].index,inplace= True )\n",
    "    # df.drop( df[df[feature] < (np.percentile(df[feature],25) - iqr)].index,inplace= True )\n",
    "\n",
    "    df.loc[df[feature] > (iqr + np.percentile(df[feature],75))] = df[feature].mean()\n",
    "    df.loc[df[feature] < (np.percentile(df[feature],25) - iqr)] = df[feature].mean()\n",
    "    #df[feature] = df[feature].fillna(df[feature].mean())\n",
    "   \n",
    "\n",
    "for i in df_test.columns:\n",
    "    if i not in cat:\n",
    "        drop_outliers_IQR(df_test,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The test data is ready and could be now applied to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets apply the best model for which we got the highest AUC_ROC Score i.e XGBoost or Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Pred_final = model_XGB.predict(df_test)\n",
    "\n",
    "# Here Y_Pred_final is the final data prepared by us now we need to upload it to  kaggle.\n",
    "\n",
    "\n",
    "print(type(Y_Pred_final))\n",
    "print(type(id_column))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the Data for Kaggle Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle = id_column.to_frame()\n",
    "\n",
    "df_kaggle['TARGET'] = Y_Pred_final.tolist()\n",
    "\n",
    "df_kaggle.to_csv('./Test_Output/Submission_XG.csv',index= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
